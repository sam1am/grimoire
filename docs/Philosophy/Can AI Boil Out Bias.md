There is much concern about the problem of bias in AI. Because it is a problem, much attention is being given to it. The engineers are on the case. What is bias? How do you define it? What numbers can you attach to it? 

With all of this work being done on bias, is it possible that we will live in a future where bias is not extremely well understood and corrected for or at least disclosed? If not by the entity distributing the content then by our own AI companions that will be watching out for us on our behalf? 

Studying bias can only help us understand it, correct for it, call it out, make it obvious. 

This is one reason to believe our AI future may be bright. 

But on the other hand, many will reject anything that tells them that they might be wrong. Still... I think our AI companions of the future will be very compelling partners. Maybe even more rewarding in some ways than traditional social connections (like those found at church).  They will be irresistible.  

There is much to wade through.


